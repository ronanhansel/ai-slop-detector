{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78ed37b",
   "metadata": {},
   "source": [
    "# DATA PREPARATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bcffa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commenter_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_content</th>\n",
       "      <th>cleaned_content_LSA</th>\n",
       "      <th>cleaned_content_LIWC</th>\n",
       "      <th>num_emojis</th>\n",
       "      <th>num_text_emojis</th>\n",
       "      <th>num_caps_words</th>\n",
       "      <th>num_unicode_chars</th>\n",
       "      <th>contains_media</th>\n",
       "      <th>contains_link</th>\n",
       "      <th>num_tagged_people</th>\n",
       "      <th>tagged_grok</th>\n",
       "      <th>used_slang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdamParkhomenko</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>https://t.co/rAkU7CWOVE</td>\n",
       "      <td>link</td>\n",
       "      <td>link</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SusanSaoirse</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko Thing is, a good number of ma...</td>\n",
       "      <td>thing good number maga use medicaid medicare t...</td>\n",
       "      <td>thing is, a good number of maga use medicaid o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RealStarTrump</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko You‚Äôre a lying bastard. https...</td>\n",
       "      <td>you lying bastard link</td>\n",
       "      <td>you are a lying bastard. link</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catothewis13876</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko The false premise is that ill...</td>\n",
       "      <td>false premise illegals get less than american ...</td>\n",
       "      <td>the false premise is that illegals get less th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masterson11776</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko Emergency rooms in So Cal are...</td>\n",
       "      <td>emergency rooms so cal full illegal brown people</td>\n",
       "      <td>emergency rooms in so cal are full of illegal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      commenter_id  comment_id  parent_id  post_id  \\\n",
       "0  AdamParkhomenko           1        NaN        1   \n",
       "1     SusanSaoirse           2        1.0        1   \n",
       "2    RealStarTrump           3        1.0        1   \n",
       "3  catothewis13876           4        1.0        1   \n",
       "4   masterson11776           5        1.0        1   \n",
       "\n",
       "                                     comment_content  \\\n",
       "0                            https://t.co/rAkU7CWOVE   \n",
       "1  @AdamParkhomenko Thing is, a good number of ma...   \n",
       "2  @AdamParkhomenko You‚Äôre a lying bastard. https...   \n",
       "3  @AdamParkhomenko The false premise is that ill...   \n",
       "4  @AdamParkhomenko Emergency rooms in So Cal are...   \n",
       "\n",
       "                                 cleaned_content_LSA  \\\n",
       "0                                               link   \n",
       "1  thing good number maga use medicaid medicare t...   \n",
       "2                             you lying bastard link   \n",
       "3  false premise illegals get less than american ...   \n",
       "4   emergency rooms so cal full illegal brown people   \n",
       "\n",
       "                                cleaned_content_LIWC  num_emojis  \\\n",
       "0                                               link           0   \n",
       "1  thing is, a good number of maga use medicaid o...           0   \n",
       "2                      you are a lying bastard. link           0   \n",
       "3  the false premise is that illegals get less th...           0   \n",
       "4  emergency rooms in so cal are full of illegal ...           0   \n",
       "\n",
       "   num_text_emojis  num_caps_words  num_unicode_chars  contains_media  \\\n",
       "0                0               0                  0           False   \n",
       "1                0               0                  0           False   \n",
       "2                0               0                  1           False   \n",
       "3                0               0                  0           False   \n",
       "4                0               0                  1           False   \n",
       "\n",
       "   contains_link  num_tagged_people  tagged_grok  used_slang  \n",
       "0           True                  0        False       False  \n",
       "1          False                  0        False       False  \n",
       "2           True                  0        False       False  \n",
       "3           True                  0        False       False  \n",
       "4          False                  0        False       False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = \"../data_preparation/outputs/version_251130/processed.csv\"\n",
    "columns = [\n",
    "    \"commenter_id\", \"comment_id\", \"parent_id\", \"post_id\", \"comment_content\",\n",
    "    \"cleaned_content_LSA\", \"cleaned_content_LIWC\", \"num_emojis\", \"num_text_emojis\",\n",
    "    \"num_caps_words\", \"num_unicode_chars\", \"contains_media\", \"contains_link\",\n",
    "    \"num_tagged_people\", \"tagged_grok\", \"used_slang\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(csv_path, usecols=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b21f46",
   "metadata": {},
   "source": [
    "Loaded content are cleaned text. We will perform double check to see if any further cleaning is needed. Here is the checklist:\n",
    "- Case normalization\n",
    "- Remove digits and words with digits\n",
    "- Remove punctuation\n",
    "- Remove special characters\n",
    "- Remove extra whitespace\n",
    "- Handle contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9eee91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_cleaning(df, columns_to_check, output_log_path=\"cleaning_validation_log.csv\", digits_log_path=\"digits_words.txt\"):\n",
    "    \"\"\"\n",
    "    Validates that text columns meet specific cleaning criteria:\n",
    "    - Lowercase\n",
    "    - No digits\n",
    "    - No punctuation/special chars\n",
    "    - No extra whitespace\n",
    "    - No contractions (implied by no punctuation/apostrophes)\n",
    "    \n",
    "    For failures:\n",
    "    - If \"Contains digits\", log the word containing digits to a txt file.\n",
    "    - For other failures (not NaN or digits), log to CSV and list them.\n",
    "    \n",
    "    Returns: True if all rows pass, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    failed_rows = []\n",
    "    digits_words = []\n",
    "    \n",
    "    # Regex patterns\n",
    "    pat_digits = re.compile(r'\\d')\n",
    "    # Matches anything that is NOT a word char (a-z) or whitespace. \n",
    "    # This catches punctuation, symbols, and apostrophes (contractions).\n",
    "    pat_punct_special = re.compile(r'[^\\w\\s]') \n",
    "    pat_double_space = re.compile(r'\\s{2,}')\n",
    "    # Pattern to find words containing digits\n",
    "    pat_word_with_digits = re.compile(r'\\b\\w*\\d\\w*\\b')\n",
    "\n",
    "    print(f\"Starting validation on columns: {columns_to_check}...\")\n",
    "\n",
    "    for col in columns_to_check:\n",
    "        for index, row in df.iterrows():\n",
    "            text = row[col]\n",
    "            \n",
    "            # Handle NaN/Float values\n",
    "            if pd.isna(text):\n",
    "                # Skip NaN as per user request (do not log)\n",
    "                continue\n",
    "\n",
    "            text = str(text)\n",
    "            reasons = []\n",
    "\n",
    "            # 1. Case normalization check\n",
    "            if not text.islower() and text != \"\":\n",
    "                reasons.append(\"Contains uppercase\")\n",
    "\n",
    "            # 2. Digits check\n",
    "            if pat_digits.search(text):\n",
    "                # Find words with digits and log them\n",
    "                words_with_digits = pat_word_with_digits.findall(text)\n",
    "                digits_words.extend(words_with_digits)\n",
    "                # Do not add to reasons for CSV logging\n",
    "            else:\n",
    "                # Only check other issues if no digits\n",
    "                # 3. Punctuation / Special Characters / Contractions check\n",
    "                if pat_punct_special.search(text):\n",
    "                    reasons.append(\"Contains punctuation/special chars/apostrophes\")\n",
    "\n",
    "                # 4. Whitespace check\n",
    "                if text != text.strip():\n",
    "                    reasons.append(\"Leading/Trailing whitespace\")\n",
    "                if pat_double_space.search(text):\n",
    "                    reasons.append(\"Contains double spaces\")\n",
    "\n",
    "            # If any non-digits reasons failed, log the row\n",
    "            if reasons:\n",
    "                failed_rows.append({\n",
    "                    \"row_index\": index,\n",
    "                    \"comment_id\": row.get(\"comment_id\", \"N/A\"),\n",
    "                    \"column\": col,\n",
    "                    \"original_text\": text,\n",
    "                    \"reason\": \"; \".join(reasons)\n",
    "                })\n",
    "\n",
    "    # Log digits words to txt file\n",
    "    if digits_words:\n",
    "        with open(digits_log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for word in set(digits_words):  # Use set to avoid duplicates\n",
    "                f.write(word + \"\\n\")\n",
    "        print(f\"üìù Words containing digits logged to: {digits_log_path}\")\n",
    "\n",
    "    # Generate Report for other failures\n",
    "    if failed_rows:\n",
    "        error_df = pd.DataFrame(failed_rows)\n",
    "        error_df.to_csv(output_log_path, index=False)\n",
    "        print(f\"‚ùå Validation FAILED.\")\n",
    "        print(f\"Found {len(failed_rows)} non-digits issues. Log saved to: {output_log_path}\")\n",
    "        print(\"Listing all failed cases (non-NaN, non-digits):\")\n",
    "        for _, row in error_df.iterrows():\n",
    "            print(f\"Row {row['row_index']}: {row['original_text']} - Reason: {row['reason']}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"‚úÖ Validation PASSED. All text is clean (ignoring digits and NaN).\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2cbbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation on columns: ['cleaned_content_LSA']...\n",
      "üìù Words containing digits logged to: digits_words.txt\n",
      "‚ùå Validation FAILED.\n",
      "Found 3 non-digits issues. Log saved to: cleaning_errors.csv\n",
      "Listing all failed cases (non-NaN, non-digits):\n",
      "Row 83208: intolerance demanding tolerance--gt very well put i like your wording - Reason: Contains punctuation/special chars/apostrophes\n",
      "Row 100415: when you make rational conversation impossible you make irrational conversation inevitable-tag - Reason: Contains punctuation/special chars/apostrophes\n",
      "Row 117680: spot on--facts facts my opinions my own i stand them - Reason: Contains punctuation/special chars/apostrophes\n"
     ]
    }
   ],
   "source": [
    "cols_to_validate = [\"cleaned_content_LSA\"]\n",
    "is_valid = validate_cleaning(df, cols_to_validate, \"cleaning_errors.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f5ae87",
   "metadata": {},
   "source": [
    "# Install necessary packages\n",
    "\n",
    "```bash\n",
    "!pip install nltk\n",
    "```\n",
    "\n",
    "Then, download the necessary NLTK resources:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('words')\n",
    "```\n",
    "\n",
    "Beside \"words\", you might also consider downloading 'punkt' and 'stopwords' if needed for further text processing:\n",
    "\n",
    "```python\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import words\n",
    "english_vocab = set(words.words())\n",
    "print('stupid' in english_vocab)  # True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
