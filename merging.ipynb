{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35c1b131",
   "metadata": {},
   "source": [
    "# Data Merging\n",
    "This notebook merges `empath_features.csv`, `lsa_features.csv`, and `processed_comments.csv` into a single pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b4dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Datasets loaded successfully.\n",
      "\n",
      "Empath Features Shape: (139407, 194)\n",
      "LSA Features Shape: (139407, 62)\n",
      "Processed Comments Shape: (139407, 15)\n",
      "\n",
      "--- Empath Features Columns (First 5) ---\n",
      "['help', 'office', 'dance', 'money', 'wedding']\n",
      "\n",
      "--- LSA Features Columns (First 5) ---\n",
      "['lsa_dim_0', 'lsa_dim_1', 'lsa_dim_2', 'lsa_dim_3', 'lsa_dim_4']\n",
      "\n",
      "--- Processed Comments Columns (First 5) ---\n",
      "['commenter_id', 'comment_id', 'parent_id', 'post_id', 'comment_content']\n",
      "\n",
      "All dataframes have the same number of rows. Ready to merge.\n",
      "Datasets loaded successfully.\n",
      "\n",
      "Empath Features Shape: (139407, 194)\n",
      "LSA Features Shape: (139407, 62)\n",
      "Processed Comments Shape: (139407, 15)\n",
      "\n",
      "--- Empath Features Columns (First 5) ---\n",
      "['help', 'office', 'dance', 'money', 'wedding']\n",
      "\n",
      "--- LSA Features Columns (First 5) ---\n",
      "['lsa_dim_0', 'lsa_dim_1', 'lsa_dim_2', 'lsa_dim_3', 'lsa_dim_4']\n",
      "\n",
      "--- Processed Comments Columns (First 5) ---\n",
      "['commenter_id', 'comment_id', 'parent_id', 'post_id', 'comment_content']\n",
      "\n",
      "All dataframes have the same number of rows. Ready to merge.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define file paths\n",
    "data_dir = 'data-ai-slop-detector'\n",
    "empath_path = os.path.join(data_dir, 'empath_features.csv')\n",
    "lsa_path = os.path.join(data_dir, 'lsa_features.csv')\n",
    "comments_path = os.path.join(data_dir, 'processed_comments.csv')\n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "try:\n",
    "    df_empath = pd.read_csv(empath_path)\n",
    "    df_lsa = pd.read_csv(lsa_path)\n",
    "    df_comments = pd.read_csv(comments_path)\n",
    "    \n",
    "    print(\"Datasets loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading files: {e}\")\n",
    "\n",
    "# Inspect the dataframes\n",
    "print(f\"\\nEmpath Features Shape: {df_empath.shape}\")\n",
    "print(f\"LSA Features Shape: {df_lsa.shape}\")\n",
    "print(f\"Processed Comments Shape: {df_comments.shape}\")\n",
    "\n",
    "print(\"\\n--- Empath Features Columns (First 5) ---\")\n",
    "print(df_empath.columns.tolist()[:5])\n",
    "\n",
    "print(\"\\n--- LSA Features Columns (First 5) ---\")\n",
    "print(df_lsa.columns.tolist()[:5])\n",
    "\n",
    "print(\"\\n--- Processed Comments Columns (First 5) ---\")\n",
    "print(df_comments.columns.tolist()[:5])\n",
    "\n",
    "# Check for length mismatch\n",
    "if len(df_empath) == len(df_lsa) == len(df_comments):\n",
    "    print(\"\\nAll dataframes have the same number of rows. Ready to merge.\")\n",
    "else:\n",
    "    print(\"\\nWARNING: Row counts do not match!\")\n",
    "    print(\"Merging by index might be incorrect if rows are not aligned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c1124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataframes...\n",
      "Saving merged data to data-ai-slop-detector/merged_data.pkl...\n",
      "Done.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Merge the dataframes\n",
    "# Note: This assumes the rows are aligned by index.\n",
    "if len(df_empath) == len(df_lsa) == len(df_comments):\n",
    "    print(\"Merging dataframes...\")\n",
    "    df_merged = pd.concat([df_comments, df_empath, df_lsa], axis=1)\n",
    "    \n",
    "    # Save to pickle\n",
    "    output_path = os.path.join(data_dir, 'merged_data.pkl')\n",
    "    print(f\"Saving merged data to {output_path}...\")\n",
    "    df_merged.to_pickle(output_path)\n",
    "    print(\"Done.\")\n",
    "else:\n",
    "    print(\"Skipping merge due to row count mismatch. Please investigate the data alignment.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f0d875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d86b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commenter_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_content</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>num_emojis</th>\n",
       "      <th>num_text_emojis</th>\n",
       "      <th>num_caps_words</th>\n",
       "      <th>num_unicode_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>lsa_dim_52</th>\n",
       "      <th>lsa_dim_53</th>\n",
       "      <th>lsa_dim_54</th>\n",
       "      <th>lsa_dim_55</th>\n",
       "      <th>lsa_dim_56</th>\n",
       "      <th>lsa_dim_57</th>\n",
       "      <th>lsa_dim_58</th>\n",
       "      <th>lsa_dim_59</th>\n",
       "      <th>lsa_dim_60</th>\n",
       "      <th>lsa_dim_61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdamParkhomenko</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>https://t.co/rAkU7CWOVE</td>\n",
       "      <td>link</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>-0.000344</td>\n",
       "      <td>-0.000402</td>\n",
       "      <td>-0.000916</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SusanSaoirse</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko Thing is, a good number of ma...</td>\n",
       "      <td>thing good number maga use medicaid oregon med...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032935</td>\n",
       "      <td>0.042518</td>\n",
       "      <td>-0.009026</td>\n",
       "      <td>0.020254</td>\n",
       "      <td>-0.004191</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.007515</td>\n",
       "      <td>-0.014450</td>\n",
       "      <td>-0.000272</td>\n",
       "      <td>-0.019075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RealStarTrump</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko You’re a lying bastard. https...</td>\n",
       "      <td>youre lying bastard link</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006881</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.010444</td>\n",
       "      <td>-0.002105</td>\n",
       "      <td>-0.013546</td>\n",
       "      <td>0.006378</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catothewis13876</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko The false premise is that ill...</td>\n",
       "      <td>false premise illegals get less than american ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019162</td>\n",
       "      <td>0.061776</td>\n",
       "      <td>-0.055354</td>\n",
       "      <td>-0.008987</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>-0.005087</td>\n",
       "      <td>-0.059042</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.034343</td>\n",
       "      <td>-0.005884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masterson11776</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko Emergency rooms in So Cal are...</td>\n",
       "      <td>emergency rooms indiana so cal full illegal br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>-0.019525</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>-0.004874</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>-0.008425</td>\n",
       "      <td>-0.007787</td>\n",
       "      <td>-0.004375</td>\n",
       "      <td>-0.002130</td>\n",
       "      <td>-0.005013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139402</th>\n",
       "      <td>ColborneGreg</td>\n",
       "      <td>139403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>i just received push notification nvidia adver...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>-0.032044</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>-0.016273</td>\n",
       "      <td>-0.022032</td>\n",
       "      <td>-0.014603</td>\n",
       "      <td>-0.027949</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>-0.015425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139403</th>\n",
       "      <td>trust_Mina</td>\n",
       "      <td>139404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>wow seeing indiana nyc makes maine feel so luc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085519</td>\n",
       "      <td>-0.004203</td>\n",
       "      <td>-0.065151</td>\n",
       "      <td>-0.042522</td>\n",
       "      <td>0.104675</td>\n",
       "      <td>0.088470</td>\n",
       "      <td>0.076652</td>\n",
       "      <td>0.033047</td>\n",
       "      <td>0.095929</td>\n",
       "      <td>-0.017154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>damnThoughtful</td>\n",
       "      <td>139405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>useless gimped bandwidth buy gpu instead</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001759</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.004070</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>honasu</td>\n",
       "      <td>139406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>nvidia marketing play horrible part positionin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033805</td>\n",
       "      <td>-0.065463</td>\n",
       "      <td>-0.013342</td>\n",
       "      <td>0.032919</td>\n",
       "      <td>0.047874</td>\n",
       "      <td>0.043419</td>\n",
       "      <td>-0.010128</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.020415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>ArnaldoCapo</td>\n",
       "      <td>139407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>ive not so much fomo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015297</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.025280</td>\n",
       "      <td>0.019753</td>\n",
       "      <td>-0.043773</td>\n",
       "      <td>-0.014637</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>-0.000791</td>\n",
       "      <td>0.047009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139407 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           commenter_id  comment_id  parent_id  post_id  \\\n",
       "0       AdamParkhomenko           1        NaN        1   \n",
       "1          SusanSaoirse           2        1.0        1   \n",
       "2         RealStarTrump           3        1.0        1   \n",
       "3       catothewis13876           4        1.0        1   \n",
       "4        masterson11776           5        1.0        1   \n",
       "...                 ...         ...        ...      ...   \n",
       "139402     ColborneGreg      139403        NaN       44   \n",
       "139403       trust_Mina      139404        NaN       44   \n",
       "139404   damnThoughtful      139405        NaN       44   \n",
       "139405           honasu      139406        NaN       44   \n",
       "139406      ArnaldoCapo      139407        NaN       44   \n",
       "\n",
       "                                          comment_content  \\\n",
       "0                                 https://t.co/rAkU7CWOVE   \n",
       "1       @AdamParkhomenko Thing is, a good number of ma...   \n",
       "2       @AdamParkhomenko You’re a lying bastard. https...   \n",
       "3       @AdamParkhomenko The false premise is that ill...   \n",
       "4       @AdamParkhomenko Emergency rooms in So Cal are...   \n",
       "...                                                   ...   \n",
       "139402  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139403  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139404  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139405  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139406  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "\n",
       "                                          cleaned_content  num_emojis  \\\n",
       "0                                                    link           0   \n",
       "1       thing good number maga use medicaid oregon med...           0   \n",
       "2                                youre lying bastard link           0   \n",
       "3       false premise illegals get less than american ...           0   \n",
       "4       emergency rooms indiana so cal full illegal br...           0   \n",
       "...                                                   ...         ...   \n",
       "139402  i just received push notification nvidia adver...           0   \n",
       "139403  wow seeing indiana nyc makes maine feel so luc...           1   \n",
       "139404           useless gimped bandwidth buy gpu instead           0   \n",
       "139405  nvidia marketing play horrible part positionin...           0   \n",
       "139406                               ive not so much fomo           0   \n",
       "\n",
       "        num_text_emojis  num_caps_words  num_unicode_chars  ...  lsa_dim_52  \\\n",
       "0                     0               0                  0  ...    0.000013   \n",
       "1                     0               0                  0  ...    0.032935   \n",
       "2                     0               0                  1  ...   -0.006881   \n",
       "3                     0               0                  0  ...    0.019162   \n",
       "4                     0               0                  1  ...    0.014652   \n",
       "...                 ...             ...                ...  ...         ...   \n",
       "139402                0               2                  0  ...    0.000021   \n",
       "139403                0               3                  2  ...   -0.085519   \n",
       "139404                0               1                  0  ...   -0.001759   \n",
       "139405                0               2                  0  ...   -0.033805   \n",
       "139406                0               1                  1  ...    0.015297   \n",
       "\n",
       "        lsa_dim_53  lsa_dim_54  lsa_dim_55  lsa_dim_56  lsa_dim_57  \\\n",
       "0        -0.000126   -0.000344   -0.000402   -0.000916    0.000051   \n",
       "1         0.042518   -0.009026    0.020254   -0.004191    0.003561   \n",
       "2         0.000761    0.006115    0.010444   -0.002105   -0.013546   \n",
       "3         0.061776   -0.055354   -0.008987    0.013624   -0.005087   \n",
       "4        -0.019525   -0.003320   -0.004874    0.007576   -0.008425   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "139402   -0.019260   -0.032044    0.004067   -0.016273   -0.022032   \n",
       "139403   -0.004203   -0.065151   -0.042522    0.104675    0.088470   \n",
       "139404   -0.003599    0.003692   -0.000820   -0.004070    0.000330   \n",
       "139405   -0.065463   -0.013342    0.032919    0.047874    0.043419   \n",
       "139406    0.002412    0.000868    0.025280    0.019753   -0.043773   \n",
       "\n",
       "        lsa_dim_58  lsa_dim_59  lsa_dim_60  lsa_dim_61  \n",
       "0         0.000233    0.000026    0.000140    0.000635  \n",
       "1         0.007515   -0.014450   -0.000272   -0.019075  \n",
       "2         0.006378    0.002457   -0.002760    0.000702  \n",
       "3        -0.059042   -0.005017   -0.034343   -0.005884  \n",
       "4        -0.007787   -0.004375   -0.002130   -0.005013  \n",
       "...            ...         ...         ...         ...  \n",
       "139402   -0.014603   -0.027949    0.053836   -0.015425  \n",
       "139403    0.076652    0.033047    0.095929   -0.017154  \n",
       "139404    0.001171    0.001398    0.000775    0.000464  \n",
       "139405   -0.010128    0.005432   -0.000098    0.020415  \n",
       "139406   -0.014637    0.042394   -0.000791    0.047009  \n",
       "\n",
       "[139407 rows x 271 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d19b66",
   "metadata": {},
   "source": [
    "# Twitter NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c87fa30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TweetNLP models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/slop/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1317: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/slop/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:1025: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/slop/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:1025: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/slop/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/anaconda/envs/slop/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded.\n",
      "Running NLP analysis on comments...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22f52bcd8680451ba86d27f4be57c89a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139407 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging with Empath and LSA features...\n",
      "Final merged shape: (139407, 279)\n",
      "Saved to data-ai-slop-detector/final_merged_data_nlp.pkl\n",
      "Saved to data-ai-slop-detector/final_merged_data_nlp.pkl\n"
     ]
    }
   ],
   "source": [
    "# Ensure ipywidgets is available for notebook progress bars; install if missing.\n",
    "try:\n",
    "    import ipywidgets  # noqa\n",
    "except Exception:\n",
    "    %pip install ipywidgets jupyterlab_widgets\n",
    "\n",
    "import tweetnlp\n",
    "import numpy as np\n",
    "# Prefer notebook widgets, but fall back to auto version if widgets are unavailable.\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except Exception:\n",
    "    from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Ensure models are loaded\n",
    "print(\"Loading TweetNLP models...\")\n",
    "# Load models once to avoid reloading for every comment\n",
    "try:\n",
    "    model_sentiment = tweetnlp.load_model('sentiment')\n",
    "    model_irony = tweetnlp.load_model('irony')\n",
    "    model_hate = tweetnlp.load_model('hate')\n",
    "    model_offensive = tweetnlp.load_model('offensive')\n",
    "    print(\"Models loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading models: {e}\")\n",
    "\n",
    "def analyze_comment(text):\n",
    "    if not isinstance(text, str):\n",
    "        return pd.Series([None]*8)\n",
    "    \n",
    "    try:\n",
    "        # Sentiment\n",
    "        s = model_sentiment.sentiment(text, return_probability=True)\n",
    "        s_label = s['label']\n",
    "        # probability is a dict like {'positive': 0.9, ...}\n",
    "        s_prob = s['probability'][s_label] \n",
    "        \n",
    "        # Irony\n",
    "        i = model_irony.irony(text, return_probability=True)\n",
    "        i_label = i['label']\n",
    "        i_prob = i['probability'][i_label]\n",
    "\n",
    "        # Hate\n",
    "        h = model_hate.hate(text, return_probability=True)\n",
    "        h_label = h['label']\n",
    "        h_prob = h['probability'][h_label]\n",
    "\n",
    "        # Offensive\n",
    "        o = model_offensive.offensive(text, return_probability=True)\n",
    "        o_label = o['label']\n",
    "        o_prob = o['probability'][o_label]\n",
    "        \n",
    "        return pd.Series([s_label, s_prob, i_label, i_prob, h_label, h_prob, o_label, o_prob])\n",
    "    except Exception:\n",
    "        return pd.Series([None]*8)\n",
    "\n",
    "# Run analysis\n",
    "print(\"Running NLP analysis on comments...\")\n",
    "nlp_cols = ['sentiment_label', 'sentiment_prob', 'irony_label', 'irony_prob', \n",
    "            'hate_label', 'hate_prob', 'offensive_label', 'offensive_prob']\n",
    "\n",
    "# Use processed_comments dataframe loaded earlier\n",
    "# We use 'comment_content' for analysis\n",
    "if 'df_comments' in locals():\n",
    "    df_nlp = df_comments['comment_content'].progress_apply(analyze_comment)\n",
    "    df_nlp.columns = nlp_cols\n",
    "\n",
    "    # Merge NLP results with comments\n",
    "    df_comments_nlp = pd.concat([df_comments, df_nlp], axis=1)\n",
    "\n",
    "    # Merge with Empath and LSA\n",
    "    print(\"Merging with Empath and LSA features...\")\n",
    "    # Note: This assumes index alignment. \n",
    "    # If rows differ, pandas aligns by index (0 to N).\n",
    "    df_final = pd.concat([df_comments_nlp, df_empath, df_lsa], axis=1)\n",
    "\n",
    "    print(f\"Final merged shape: {df_final.shape}\")\n",
    "\n",
    "    # Save\n",
    "    output_pkl = os.path.join(data_dir, 'final_merged_data_nlp.pkl')\n",
    "    df_final.to_pickle(output_pkl)\n",
    "    print(f\"Saved to {output_pkl}\")\n",
    "else:\n",
    "    print(\"df_comments is not defined. Please run the data loading cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe1bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commenter_id</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_content</th>\n",
       "      <th>cleaned_content</th>\n",
       "      <th>num_emojis</th>\n",
       "      <th>num_text_emojis</th>\n",
       "      <th>num_caps_words</th>\n",
       "      <th>num_unicode_chars</th>\n",
       "      <th>...</th>\n",
       "      <th>tagged_grok</th>\n",
       "      <th>used_slang</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentiment_prob</th>\n",
       "      <th>irony_label</th>\n",
       "      <th>irony_prob</th>\n",
       "      <th>hate_label</th>\n",
       "      <th>hate_prob</th>\n",
       "      <th>offensive_label</th>\n",
       "      <th>offensive_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdamParkhomenko</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>https://t.co/rAkU7CWOVE</td>\n",
       "      <td>link</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.655992</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.509043</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.990611</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.694312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SusanSaoirse</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko Thing is, a good number of ma...</td>\n",
       "      <td>thing good number maga use medicaid oregon med...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.491858</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.528372</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.829080</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.807302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RealStarTrump</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko You’re a lying bastard. https...</td>\n",
       "      <td>youre lying bastard link</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.938928</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.690144</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>offensive</td>\n",
       "      <td>0.906779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>catothewis13876</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko The false premise is that ill...</td>\n",
       "      <td>false premise illegals get less than american ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.803585</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.940728</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.850179</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.609643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masterson11776</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>@AdamParkhomenko Emergency rooms in So Cal are...</td>\n",
       "      <td>emergency rooms indiana so cal full illegal br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.584216</td>\n",
       "      <td>irony</td>\n",
       "      <td>0.585547</td>\n",
       "      <td>HATE</td>\n",
       "      <td>0.937815</td>\n",
       "      <td>offensive</td>\n",
       "      <td>0.640669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139402</th>\n",
       "      <td>ColborneGreg</td>\n",
       "      <td>139403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>i just received push notification nvidia adver...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.677940</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.899829</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.996151</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.921061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139403</th>\n",
       "      <td>trust_Mina</td>\n",
       "      <td>139404</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>wow seeing indiana nyc makes maine feel so luc...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.987714</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.893695</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.998502</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.946042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139404</th>\n",
       "      <td>damnThoughtful</td>\n",
       "      <td>139405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>useless gimped bandwidth buy gpu instead</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.894669</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.900792</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.988562</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.690830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139405</th>\n",
       "      <td>honasu</td>\n",
       "      <td>139406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>nvidia marketing play horrible part positionin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.613019</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.997851</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.886043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139406</th>\n",
       "      <td>ArnaldoCapo</td>\n",
       "      <td>139407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44</td>\n",
       "      <td>@nvidia @ylecun @soumithchintala @Meta @nyuniv...</td>\n",
       "      <td>ive not so much fomo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.465828</td>\n",
       "      <td>non_irony</td>\n",
       "      <td>0.897573</td>\n",
       "      <td>NOT-HATE</td>\n",
       "      <td>0.996134</td>\n",
       "      <td>non-offensive</td>\n",
       "      <td>0.896237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139407 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           commenter_id  comment_id  parent_id  post_id  \\\n",
       "0       AdamParkhomenko           1        NaN        1   \n",
       "1          SusanSaoirse           2        1.0        1   \n",
       "2         RealStarTrump           3        1.0        1   \n",
       "3       catothewis13876           4        1.0        1   \n",
       "4        masterson11776           5        1.0        1   \n",
       "...                 ...         ...        ...      ...   \n",
       "139402     ColborneGreg      139403        NaN       44   \n",
       "139403       trust_Mina      139404        NaN       44   \n",
       "139404   damnThoughtful      139405        NaN       44   \n",
       "139405           honasu      139406        NaN       44   \n",
       "139406      ArnaldoCapo      139407        NaN       44   \n",
       "\n",
       "                                          comment_content  \\\n",
       "0                                 https://t.co/rAkU7CWOVE   \n",
       "1       @AdamParkhomenko Thing is, a good number of ma...   \n",
       "2       @AdamParkhomenko You’re a lying bastard. https...   \n",
       "3       @AdamParkhomenko The false premise is that ill...   \n",
       "4       @AdamParkhomenko Emergency rooms in So Cal are...   \n",
       "...                                                   ...   \n",
       "139402  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139403  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139404  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139405  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "139406  @nvidia @ylecun @soumithchintala @Meta @nyuniv...   \n",
       "\n",
       "                                          cleaned_content  num_emojis  \\\n",
       "0                                                    link           0   \n",
       "1       thing good number maga use medicaid oregon med...           0   \n",
       "2                                youre lying bastard link           0   \n",
       "3       false premise illegals get less than american ...           0   \n",
       "4       emergency rooms indiana so cal full illegal br...           0   \n",
       "...                                                   ...         ...   \n",
       "139402  i just received push notification nvidia adver...           0   \n",
       "139403  wow seeing indiana nyc makes maine feel so luc...           1   \n",
       "139404           useless gimped bandwidth buy gpu instead           0   \n",
       "139405  nvidia marketing play horrible part positionin...           0   \n",
       "139406                               ive not so much fomo           0   \n",
       "\n",
       "        num_text_emojis  num_caps_words  num_unicode_chars  ...  tagged_grok  \\\n",
       "0                     0               0                  0  ...        False   \n",
       "1                     0               0                  0  ...        False   \n",
       "2                     0               0                  1  ...        False   \n",
       "3                     0               0                  0  ...        False   \n",
       "4                     0               0                  1  ...        False   \n",
       "...                 ...             ...                ...  ...          ...   \n",
       "139402                0               2                  0  ...        False   \n",
       "139403                0               3                  2  ...        False   \n",
       "139404                0               1                  0  ...        False   \n",
       "139405                0               2                  0  ...        False   \n",
       "139406                0               1                  1  ...        False   \n",
       "\n",
       "        used_slang  sentiment_label  sentiment_prob  irony_label irony_prob  \\\n",
       "0             True          neutral        0.655992    non_irony   0.509043   \n",
       "1             True         negative        0.491858    non_irony   0.528372   \n",
       "2             True         negative        0.938928    non_irony   0.690144   \n",
       "3             True         negative        0.803585        irony   0.940728   \n",
       "4             True         negative        0.584216        irony   0.585547   \n",
       "...            ...              ...             ...          ...        ...   \n",
       "139402        True         negative        0.677940    non_irony   0.899829   \n",
       "139403        True         positive        0.987714    non_irony   0.893695   \n",
       "139404       False         negative        0.894669    non_irony   0.900792   \n",
       "139405        True         negative        0.613019    non_irony   0.931100   \n",
       "139406        True         negative        0.465828    non_irony   0.897573   \n",
       "\n",
       "        hate_label hate_prob  offensive_label offensive_prob  \n",
       "0         NOT-HATE  0.990611    non-offensive       0.694312  \n",
       "1         NOT-HATE  0.829080    non-offensive       0.807302  \n",
       "2         NOT-HATE  0.981233        offensive       0.906779  \n",
       "3         NOT-HATE  0.850179    non-offensive       0.609643  \n",
       "4             HATE  0.937815        offensive       0.640669  \n",
       "...            ...       ...              ...            ...  \n",
       "139402    NOT-HATE  0.996151    non-offensive       0.921061  \n",
       "139403    NOT-HATE  0.998502    non-offensive       0.946042  \n",
       "139404    NOT-HATE  0.988562    non-offensive       0.690830  \n",
       "139405    NOT-HATE  0.997851    non-offensive       0.886043  \n",
       "139406    NOT-HATE  0.996134    non-offensive       0.896237  \n",
       "\n",
       "[139407 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comments_nlp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
